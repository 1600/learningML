{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import pydotplus\n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 数据导入\n",
    "xls_file = pd.ExcelFile('alliance.xls')\n",
    "# print(xls_file.sheet_names)\n",
    "df = xls_file.parse('sheet1')\n",
    "df_target = df['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 对范畴类变量进行编码\n",
    "for column in ['(L)HTTPstatus']:\n",
    "    dummies = pd.get_dummies(df[column])\n",
    "    df[dummies.columns]=dummies\n",
    "\n",
    "# 去掉已编码的原属性\n",
    "df.drop(['domain','(L)HTTPstatus'], axis=1, inplace=True)\n",
    "#df.ix[:,df.columns!=999]\n",
    "\n",
    "#去掉已编码的原属性\n",
    "#df.drop(['domain','(L)HTTPstatus','(L)超链接数量','(L)外链数量','(L)有无外部js','(L)内部js匹配','(L)外部js匹配','(L)引用图片数量','(L)WebOCR','(R)超链接数量','(R)外链数量','(R)有无外部js','(R)内部js匹配','(R)外部js匹配','(R)引用图片数量','(R)WebOCR'], axis=1, inplace=True)\n",
    "#df.ix[:,df.columns!=999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1160, 20)\n",
      "(1160,)\n"
     ]
    }
   ],
   "source": [
    "# 拆分数据集为训练集和测试集\n",
    "train, test = train_test_split(df, test_size = 0.2)   # doing split of training and testing\n",
    "train_data, train_target= train.ix[:, train.columns != 'result'], train['result']\n",
    "test_data, test_target = test.ix[:, test.columns != 'result'], test['result']\n",
    "print(train_data.shape)\n",
    "print(train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97068965517241379"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GradientBoost\n",
    "# 可控制参数为 n_estimators, max_depth\n",
    "# For datasets with a large number of classes we strongly recommend to use RandomForestClassifier as an alternative to GradientBoostingClassifier .\n",
    "#clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=2, random_state=0)\n",
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_split=1e-07, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "clf.fit(train_data,train_target)\n",
    "clf.score(train_data, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf,open('pickled_model.p','wb'))\n",
    "\n",
    "p = pickle.load(open('pickled_model.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↓↓↓↓ Test ↓↓↓↓\n",
      "Test_Accuracy >> \n",
      " [ 0.93333333  0.86666667  0.86206897  0.96551724  0.93103448  0.96551724\n",
      "  0.96551724  0.89655172  0.89655172  0.78571429]\n",
      "Test_Recall >> \n",
      " [ 0.90909091  0.81818182  0.63636364  0.90909091  0.81818182  1.          1.\n",
      "  0.90909091  1.          0.7       ]\n",
      "Test_Precision >> \n",
      " [ 0.90909091  0.81818182  1.          1.          1.          0.91666667\n",
      "  0.91666667  0.83333333  0.78571429  0.7       ]\n",
      "Test_F1 >> \n",
      " [ 0.90909091  0.81818182  0.77777778  0.95238095  0.9         0.95652174\n",
      "  0.95652174  0.86956522  0.88        0.7       ]\n"
     ]
    }
   ],
   "source": [
    "# 交叉验证\n",
    "# train_accuracy = cross_val_score(clf, train_data, train_target, cv=10,scoring='accuracy')\n",
    "# print(\"Train_Accuracy >> \\n\",train_accuracy)\n",
    "# train_recall = cross_val_score(clf, train_data, train_target, cv=10,scoring='recall')\n",
    "# print(\"Train_Recall >> \\n\",train_recall)\n",
    "# train_recall = cross_val_score(clf, train_data, train_target, cv=10,scoring='precision')\n",
    "# print(\"Train_Precision >> \\n\",train_recall)\n",
    "# train_recall = cross_val_score(clf, train_data, train_target, cv=10,scoring='f1')\n",
    "# print(\"Train_F1 >> \\n\",train_recall)\n",
    "# print(\"↑↑↑↑ Train ↑↑↑↑\")\n",
    "print(\"↓↓↓↓ Test ↓↓↓↓\")\n",
    "test_accuracy = cross_val_score(p, test_data, test_target, cv=10,scoring='accuracy')\n",
    "print(\"Test_Accuracy >> \\n\",test_accuracy)\n",
    "test_recall = cross_val_score(p, test_data, test_target, cv=10,scoring='recall')\n",
    "print(\"Test_Recall >> \\n\",test_recall)\n",
    "test_recall = cross_val_score(p, test_data, test_target, cv=10,scoring='precision')\n",
    "print(\"Test_Precision >> \\n\",test_recall)\n",
    "test_recall = cross_val_score(p, test_data, test_target, cv=10,scoring='f1')\n",
    "print(\"Test_F1 >> \\n\",test_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据导入\n",
    "to_predict_file = pd.ExcelFile('predict.xls')\n",
    "# print(xls_file.sheet_names)  # check what Sheet name the file has.\n",
    "df = to_predict_file.parse('Sheet1')\n",
    "\n",
    "# 对范畴类变量进行编码\n",
    "for column in ['(L)HTTPstatus']:\n",
    "    dummies = pd.get_dummies(df[column])\n",
    "    df[dummies.columns]=dummies\n",
    "\n",
    "# 去掉已编码的原属性\n",
    "df.drop(['domain','(L)HTTPstatus','result'], axis=1, inplace=True)\n",
    "#df.drop(['result','domain','(L)HTTPstatus','(L)超链接数量','(L)外链数量','(L)有无外部js','(L)内部js匹配','(L)外部js匹配','(L)引用图片数量','(L)WebOCR','(R)超链接数量','(R)外链数量','(R)有无外部js','(R)内部js匹配','(R)外部js匹配','(R)引用图片数量','(R)WebOCR'], axis=1, inplace=True)\n",
    "predict_set = df\n",
    "#进行预测\n",
    "p.predict(predict_set)\n",
    "#clf.predict_log_proba(predict_set)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
